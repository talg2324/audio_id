{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2M7hTxh0te4"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from scipy import stats, signal\r\n",
        "from keras.models import Model, Sequential , load_model\r\n",
        "from keras.layers import Conv2D,Conv1D, Dropout, MaxPooling2D, Flatten, Dense, Input , concatenate, MaxPooling1D, BatchNormalization, AveragePooling2D,AveragePooling1D\r\n",
        "from keras.losses import categorical_crossentropy\r\n",
        "from keras.utils import plot_model\r\n",
        "from keras.optimizers import Adam, schedules\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import Normalizer , StandardScaler\r\n",
        "from sklearn.metrics import roc_curve, roc_auc_score,auc , precision_recall_curve,  confusion_matrix, multilabel_confusion_matrix, average_precision_score, auc\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKG4gbWr0xcU",
        "outputId": "c1aad068-4370-436b-a02a-14fa765b3654"
      },
      "source": [
        "drive.mount('/content/gdrive')\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prKK6GjV2hpP"
      },
      "source": [
        "# Yariv\r\n",
        "feat_space = './drive/MyDrive/audio_colab/feats/'\r\n",
        "# Tal\r\n",
        "#feat_space = './drive/MyDrive/Voice Recording Database/Features/'\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpf0qQwB3v30"
      },
      "source": [
        "def get_names():\r\n",
        "\r\n",
        "    #feats = ['mfcc', 'del-mfcc','del-del-mfcc', 'Spect', 'rms', 'dSdT', 'dS2dT2','zero_crossing_rate', 'spectral_centroid', 'spectral_bandwidth']\r\n",
        "    feats = ['mfcc' ,'mel_spec_dev_2']\r\n",
        "    dims = {\r\n",
        "            'STFT':'image',\r\n",
        "            'Spect':'image',\r\n",
        "            'dSdT':'image',\r\n",
        "            'mel_spec_dev_2':'image',\r\n",
        "            'mfcc':'coeffs',\r\n",
        "            'del-mfcc':'coeffs',\r\n",
        "            'del-del-mfcc':'coeffs',\r\n",
        "            'rms':'stats',\r\n",
        "            'zero_crossing_rate':'stats',\r\n",
        "            'spectral_centroid':'stats',\r\n",
        "            'spectral_bandwidth':'stats'\r\n",
        "            }\r\n",
        "    return feats , dims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmMZ7iB906o8"
      },
      "source": [
        "def sort_data(feat_space,best_features = None):\r\n",
        "\r\n",
        "    X = {}\r\n",
        "    Y = {}\r\n",
        "\r\n",
        "    class_no = 0\r\n",
        "    stat_names =[\r\n",
        "            'spectral_centroid',\r\n",
        "            'spectral_bandwidth',\r\n",
        "            'rms',\r\n",
        "            'zero_crossing_rate']\r\n",
        "\r\n",
        "    for spect_path in os.listdir(feat_space):\r\n",
        "        data = {}\r\n",
        "        if '.npy' in spect_path and 'Copy' not in spect_path:\r\n",
        "            label, ind = spect_path.split('_')\r\n",
        "\r\n",
        "        obj = np.load(feat_space+spect_path, allow_pickle=True)\r\n",
        "\r\n",
        "        if best_features == None:\r\n",
        "            stats = obj[0,0]\r\n",
        "            data['STFT'] = obj[0,1]\r\n",
        "            data['mfcc'] = obj[0,2]\r\n",
        "            data['del-mfcc'] = obj[0,3]\r\n",
        "            data['del-del-mfcc'] = obj[0,4]  \r\n",
        "            data['Spect'] = obj[0,5]\r\n",
        "            data['dSdT'] = obj[0,6]\r\n",
        "            data['dS2dT2'] = obj[0,7]\r\n",
        "\r\n",
        "            for i in range(len(stat_names)):\r\n",
        "                data[stat_names[i]] = stats[i,:]\r\n",
        "\r\n",
        "        else:\r\n",
        "            for feature in range(len(best_features) ):\r\n",
        "                data[best_features[feature] ] = obj[0,feature ]\r\n",
        "            \r\n",
        "        if label not in Y.keys():\r\n",
        "          Y[label] = class_no\r\n",
        "          X[class_no] = []\r\n",
        "          class_no += 1\r\n",
        "\r\n",
        "        this_class = Y[label]\r\n",
        "        X[this_class].append(data)\r\n",
        "\r\n",
        "    return X , class_no\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTz1y_wU061T"
      },
      "source": [
        "def split_test_train_custom(X_, class_no, ratio=0.6):\r\n",
        "\r\n",
        "  X_train = []\r\n",
        "  Y_train = []\r\n",
        "  X_test = []\r\n",
        "  Y_test = []\r\n",
        "  \r\n",
        "  for i in range(class_no):\r\n",
        "\r\n",
        "      X_i = X_[i]\r\n",
        "\r\n",
        "      available_samples = len(X_i)\r\n",
        "      no_train_samples = int(available_samples*ratio)\r\n",
        "\r\n",
        "      train_samples = np.random.choice(range(available_samples), no_train_samples, replace=False)\r\n",
        "\r\n",
        "      X_train.extend([X_i[k] for k in train_samples])\r\n",
        "      Y_train.extend([i for k in range(no_train_samples)])\r\n",
        "\r\n",
        "      X_test.extend([X_i[k] for k in range(available_samples) if k not in train_samples])\r\n",
        "      Y_test.extend([i for k in range(available_samples-no_train_samples)])\r\n",
        "\r\n",
        "\r\n",
        "  return np.array(X_train), np.array(X_test), np.array(Y_train), np.array(Y_test)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfjhg3Ij06-p"
      },
      "source": [
        "def one_hot_encoder(_Y_train):\r\n",
        "\r\n",
        "    classes = _Y_train.max()+1\r\n",
        "    class_labels = np.zeros((classes))\r\n",
        "    _Y_train2 = []\r\n",
        "\r\n",
        "    for y in _Y_train:\r\n",
        "        t = np.copy(class_labels)\r\n",
        "        t[y] = 1\r\n",
        "        _Y_train2.append(t)\r\n",
        "\r\n",
        "    _Y_train2 = np.array(_Y_train2)\r\n",
        "\r\n",
        "    return _Y_train2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL4svHcW07cF"
      },
      "source": [
        "def normalize_reshape(x_train, x_test, feats):\r\n",
        "    Xtrain = {}\r\n",
        "    Xtest = {}\r\n",
        "\r\n",
        "    for f in feats:\r\n",
        "        train_len = len(x_train)\r\n",
        "        test_len = len(x_test)\r\n",
        "        orig_shape = x_train[0][f].shape\r\n",
        "        dims = len(orig_shape)\r\n",
        "        norm = Normalizer()\r\n",
        "\r\n",
        "        if dims > 1:\r\n",
        "            h,w = orig_shape\r\n",
        "            X0 = np.array([x[f].flatten() for x in x_train])\r\n",
        "            Xf = np.array([x[f].flatten() for x in x_test])\r\n",
        "\r\n",
        "            X0 = norm.fit_transform(X0).reshape(train_len, h, w)\r\n",
        "            Xf = norm.transform(Xf).reshape(test_len, h, w)\r\n",
        "\r\n",
        "        else:\r\n",
        "            l = orig_shape[0]\r\n",
        "            X0 = np.array([x[f] for x in x_train])\r\n",
        "            Xf = np.array([x[f] for x in x_test])\r\n",
        "\r\n",
        "            X0 = norm.fit_transform(X0).reshape(train_len, l, 1)\r\n",
        "            Xf = norm.transform(Xf).reshape(test_len, l, 1)\r\n",
        "\r\n",
        "        Xtrain[f] = X0\r\n",
        "        Xtest[f] = Xf\r\n",
        "\r\n",
        "    return Xtrain, Xtest\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SamcjQB1U2B"
      },
      "source": [
        "def get_model_block(inp_shape, dims, p=0.5):\r\n",
        "\r\n",
        "    if dims=='image':\r\n",
        "\r\n",
        "      inp = Input(shape= (inp_shape[0], inp_shape[1], 1))\r\n",
        "      x = Conv2D(256, kernel_size=(3,3), activation='relu', input_shape=inp_shape)(inp)\r\n",
        "      x = MaxPooling2D(pool_size=(2,2))(x)\r\n",
        "      x = Dropout(0.5*p)(x)\r\n",
        "      x = Conv2D(128, kernel_size=(3,3), activation='relu')(x)\r\n",
        "      x = MaxPooling2D(pool_size=(2,2))(x)\r\n",
        "      x = Dropout(0.75*p)(x)\r\n",
        "      x = Conv2D(64, kernel_size=(3,3), activation='relu')(x)\r\n",
        "      x = MaxPooling2D(pool_size=(2,2))(x)\r\n",
        "      x = Dropout(p)(x)\r\n",
        "      x = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\r\n",
        "      x = MaxPooling2D(pool_size=(2,2))(x)\r\n",
        "      x = Dropout(2*p)(x)\r\n",
        "      x = Conv2D(16, kernel_size=(3,3), activation='relu')(x)\r\n",
        "      x = MaxPooling2D(pool_size=(2,2))(x)\r\n",
        "      x = Dropout(2*p)(x)\r\n",
        "\r\n",
        "      \r\n",
        "      connection_layer = Flatten()(x)\r\n",
        "\r\n",
        "    if dims=='coeffs':\r\n",
        "\r\n",
        "      inp = Input(shape= (inp_shape[0], inp_shape[1], 1))\r\n",
        "      x = Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=inp_shape)(inp)\r\n",
        "      x = MaxPooling2D(pool_size=(2,2))(x)\r\n",
        "      x = Dropout(0.75*p)(x)\r\n",
        "      x = Conv2D(64, kernel_size=(3,3), activation='relu')(x)\r\n",
        "      x = MaxPooling2D(pool_size=(2,2))(x)\r\n",
        "      x = Dropout(p)(x)\r\n",
        "      x = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\r\n",
        "      x = MaxPooling2D(pool_size=(2,2))(x)\r\n",
        "      x = Dropout(2*p)(x)\r\n",
        "      #x = Conv2D(16, kernel_size=(3,3), activation='relu')(x)\r\n",
        "      #x = Dropout(2*p)(x)\r\n",
        "      \r\n",
        "      connection_layer = Flatten()(x)\r\n",
        "\r\n",
        "    if dims=='stats':\r\n",
        "      inp = Input(shape = (inp_shape[0],1) )\r\n",
        "      x = Conv1D(128, kernel_size=3, activation='relu', input_shape=inp_shape)(inp)\r\n",
        "      x = MaxPooling1D(pool_size=2)(x)\r\n",
        "      x = Dropout(2*p)(x)\r\n",
        "      x = Conv1D(64, kernel_size=3, activation='relu')(x)\r\n",
        "      x = MaxPooling1D(pool_size=2)(x)\r\n",
        "      x = Dropout(2*p)(x)\r\n",
        "      x = Conv1D(32, kernel_size=3, activation='relu')(x)\r\n",
        "      x = MaxPooling1D(pool_size=2)(x)\r\n",
        "      x = Dropout(p)(x)\r\n",
        "\r\n",
        "      connection_layer = Flatten()(x)\r\n",
        "\r\n",
        "    m = Model(inputs = inp,outputs = connection_layer)\r\n",
        "\r\n",
        "    return m\r\n",
        "\r\n",
        "def model_output(models,num_class,lr=1e-3, p=0.5):\r\n",
        "\r\n",
        "    if len(models) > 1 :\r\n",
        "      outputs = concatenate([ m.output for m in models ])\r\n",
        "      inputs = [ m.input for m in models ] \r\n",
        "\r\n",
        "    else:\r\n",
        "      outputs = concatenate([models[0].output,models[0].output])\r\n",
        "      inputs = [models[0].input]\r\n",
        "\r\n",
        "    output_layer = Dense(num_class, activation='softmax')(outputs)\r\n",
        "\r\n",
        "    lr_schedule = schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=lr,\r\n",
        "    decay_steps= 27,\r\n",
        "    decay_rate=1)\r\n",
        "\r\n",
        "    opt = Adam(lr_schedule)\r\n",
        "    m = Model(inputs = inputs ,outputs = output_layer)\r\n",
        "    m.compile(loss=categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\r\n",
        "    return m "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGUUSD8O1ZEE"
      },
      "source": [
        "def training_model(X_,dims,feats,class_no,hyper_params):\r\n",
        "\r\n",
        "  best_feats = ['mfcc', 'mel_spec_dev_2']\r\n",
        "  lr= hyper_params[0]\r\n",
        "  batch_size= hyper_params[1]\r\n",
        "  dropout_block = hyper_params[2]\r\n",
        "  dropout_out= hyper_params[3]\r\n",
        "  epochs= hyper_params[4]\r\n",
        "  split = hyper_params[5]\r\n",
        "  v = 1\r\n",
        "\r\n",
        "  x_train_best = []\r\n",
        "  x_test_best = []\r\n",
        "  m_list = []\r\n",
        "  x_train_i = []\r\n",
        "  x_test_i = []\r\n",
        "\r\n",
        "  x_train_round,x_test_round, y_train,y_test = split_test_train_custom(X_,class_no, ratio=split)\r\n",
        "\r\n",
        "  y_train = one_hot_encoder(y_train)\r\n",
        "  y_test = one_hot_encoder(y_test)\r\n",
        "  x_train_round, x_test_round = normalize_reshape(x_train_round, x_test_round, feats)\r\n",
        "\r\n",
        "  for f in best_feats:\r\n",
        "          \r\n",
        "    x_train_best.append(x_train_round[f])\r\n",
        "    x_test_best.append(x_test_round[f])\r\n",
        "\r\n",
        "    m_list.append(get_model_block(x_test_round[f][0].shape, dims[f], p=dropout_block))\r\n",
        "  \r\n",
        "  m = model_output(m_list, num_class=y_train.shape[-1],lr=lr, p=dropout_out)\r\n",
        "\r\n",
        "  x_train_i.extend([block for block in x_train_best])\r\n",
        "  x_test_i.extend([block for block in x_test_best])\r\n",
        "\r\n",
        "  h = m.fit(x_train_i, y_train, epochs=epochs, batch_size=batch_size,verbose=v,shuffle=True)\r\n",
        "  loss, acc = m.evaluate(x_test_i, y_test)\r\n",
        "  y_hat = m.predict(x_test_i)\r\n",
        "\r\n",
        "\r\n",
        "  print('train acc:' + str(max(h.history['accuracy'])))\r\n",
        "  print('test loss:' + str(loss) )\r\n",
        "  print('test acc:' + str(acc) )\r\n",
        "\r\n",
        "  #m.save_weights(filepath+'trained_model', overwrite=True, save_format=None, options=None)\r\n",
        "    \r\n",
        "  return m, y_test, y_hat, acc, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnHulfoB07jg"
      },
      "source": [
        "    feats, dims = get_names()\r\n",
        "    best_feat = ['mfcc','mel_spec_dev_2']\r\n",
        "\r\n",
        "    X , class_no = sort_data(feat_space,best_feat)\r\n",
        "\r\n",
        "    \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwn8l7-T-ARz"
      },
      "source": [
        "acc = 0\r\n",
        "while acc < 0.93 :\r\n",
        "  lr = 1e-3\r\n",
        "  batch_size = np.random.randint(2,8)*2\r\n",
        "  dropout_block = np.random.uniform(0.1,0.2)\r\n",
        "  dropout_out = np.random.uniform(0.5,0.7)\r\n",
        "  epochs = np.random.randint(40,60)\r\n",
        "  split = np.random.uniform(0.7,0.75)\r\n",
        "  hyper_params = [lr,batch_size,dropout_block,dropout_out,epochs,split] \r\n",
        "  m, y_test, y_hat, acc, loss_round = training_model(X,dims,feats,class_no,hyper_params)\r\n",
        "\r\n",
        "m.save('./drive/MyDrive/audio_colab/best_model')\r\n",
        "\r\n",
        "  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsocm-3B5kHb"
      },
      "source": [
        "reconstruct_model = load_model('./drive/MyDrive/audio_colab/best_model')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyX3HVsh7s1e"
      },
      "source": [
        "m.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXZceiyg7xBF",
        "outputId": "5d385564-27cd-49df-ff9e-2799e629e7df"
      },
      "source": [
        "x_train_best = []\r\n",
        "x_test_best = []\r\n",
        "m_list = []\r\n",
        "x_train_i = []\r\n",
        "x_test_i = []\r\n",
        "\r\n",
        "x_train_round,x_test_round, y_train,y_test = split_test_train_custom(X,class_no, ratio=split)\r\n",
        "\r\n",
        "y_train = one_hot_encoder(y_train)\r\n",
        "y_test = one_hot_encoder(y_test)\r\n",
        "x_train_round, x_test_round = normalize_reshape(x_train_round, x_test_round, feats)\r\n",
        "x_train_i.extend([block for block in x_train_round])\r\n",
        "x_test_i.extend([block for block in x_test_round])\r\n",
        "\r\n",
        "for f in feats:          \r\n",
        "    x_train_best.append(x_train_round[f])\r\n",
        "    x_test_best.append(x_test_round[f])\r\n",
        "\r\n",
        "loss, acc = reconstruct_model.evaluate(x_test_best,y_test)\r\n",
        "y_hat = reconstruct_model.predict(x_test_best)\r\n",
        "print(acc)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1209 - accuracy: 0.9524\n",
            "0.9523809552192688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EBksXwyQsE3",
        "outputId": "bd6aaefe-a81e-4c47-9f0e-60707d84331b"
      },
      "source": [
        "print(hyper_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.001, 12, 0.19002944681105188, 0.5318713254603384, 47, 0.7495872915887234]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ6BmLKg4fWy"
      },
      "source": [
        "def ROC_curve(y_test,y_hat):\r\n",
        "\r\n",
        "  fpr = dict()\r\n",
        "  tpr = dict()\r\n",
        "  thresholds = dict()\r\n",
        "  roc_auc = dict()\r\n",
        "  average_auc= dict()\r\n",
        "  \r\n",
        "  classes = np.max(y_test.argmax(axis=1))+1\r\n",
        "\r\n",
        "  #for i in range(classes):\r\n",
        "    #fpr[i], tpr[i], thresholds[i] = roc_curve(y_test[:, i], y_hat[:, i])\r\n",
        "    #roc_auc[i] = auc(fpr[i], tpr[i])\r\n",
        "   \r\n",
        "  fpr[\"micro\"], tpr[\"micro\"], thresholds = roc_curve(y_test.ravel(), y_hat.ravel() )\r\n",
        "  average_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\r\n",
        "  plt.plot(fpr['micro'],tpr['micro'])  \r\n",
        "  \r\n",
        "  plt.figure(1, figsize = (10,15) )\r\n",
        "  plt.plot([0, 1], [0, 1], 'k--')\r\n",
        "  plt.xlabel('False positive rate')\r\n",
        "  plt.ylabel('True positive rate')\r\n",
        "  plt.title('ROC curve -  Average auc score, micro-averaged over all classes: AUC={0:0.2f}'.format(average_auc[\"micro\"]))\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  return fpr, tpr, thresholds, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2YgFbdr4hiC"
      },
      "source": [
        "def PRC_curve(y_test,y_hat):\r\n",
        "\r\n",
        "  precision = dict()\r\n",
        "  recall = dict()\r\n",
        "  thresholds = dict()\r\n",
        "  average_precision = dict()\r\n",
        "  classes = np.max(y_test.argmax(axis=1))+1\r\n",
        "\r\n",
        "  #for i in range(classes):\r\n",
        "    #precision[i], recall[i], thresholds[i] = precision_recall_curve(y_test[:, i], y_hat[:, i])\r\n",
        "  precision[\"micro\"], recall[\"micro\"], thresholds = precision_recall_curve(y_test.ravel(), y_hat.ravel() )\r\n",
        "  average_precision[\"micro\"] = average_precision_score(y_test, y_hat,average=\"micro\")\r\n",
        "  plt.plot(recall['micro'],precision['micro'])\r\n",
        "  plt.ylim([0.0, 1.05])\r\n",
        "  plt.xlim([0.0, 1.0])\r\n",
        "  plt.xlabel('Recall')\r\n",
        "  plt.ylabel('Precision')\r\n",
        "  plt.title('PRC curve - Average precision score, micro-averaged over all classes: AP={0:0.2f}'.format(average_precision[\"micro\"]))\r\n",
        "  plt.show()\r\n",
        "  #plt.figure(2,figsize = (10,15) )\r\n",
        "  #[ plt.plot( recall[i],precision[i], label='class '+str(i)) for i in range(round(classes/2) ) ] \r\n",
        "  #[ plt.plot( recall[i],precision[i],'--', label='class '+str(i)) for i in range(round(classes/2),classes ) ] \r\n",
        "  return precision, recall, thresholds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIHgNrln4nRL"
      },
      "source": [
        "def operating_points(y,y_hat,classes):\r\n",
        "\r\n",
        "  best_tpr_threshold = 0\r\n",
        "  best_ppv_threshold = 0\r\n",
        "  best_acc_threshold = 0\r\n",
        "  TPR_round = 0\r\n",
        "  PPV_round = 0\r\n",
        "  ACC_round = 0\r\n",
        "  thr = 0\r\n",
        "  done = False\r\n",
        "\r\n",
        "  while not done:\r\n",
        "    \r\n",
        "    y_hat_round = y_hat > thr\r\n",
        "    cnf_matrix = confusion_matrix(y_test.argmax(axis = 1),y_hat_round.argmax(axis =1) )\r\n",
        "\r\n",
        "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \r\n",
        "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\r\n",
        "    TP = np.diag(cnf_matrix)\r\n",
        "    TN = cnf_matrix.sum() - (FP + FN + TP)\r\n",
        "\r\n",
        "    FP = FP.astype(float)\r\n",
        "    FN = FN.astype(float)\r\n",
        "    TP = TP.astype(float)\r\n",
        "    TN = TN.astype(float)\r\n",
        "\r\n",
        "    # INITIALIZE step\r\n",
        "    # Sensitivity, hit rate, recall, or true positive rate\r\n",
        "    if np.sum(TP+FN) != 0 :\r\n",
        "      TPR = TP/(TP+FN)\r\n",
        "      TPR = np.mean(TPR)\r\n",
        "\r\n",
        "    else:\r\n",
        "      TPR = 0\r\n",
        "\r\n",
        "    # Precision or positive predictive value\r\n",
        "    if np.sum(TP+FP) != 0 :\r\n",
        "      PPV = TP/(TP+FP)\r\n",
        "      PPV = np.mean(PPV)\r\n",
        "\r\n",
        "    else:\r\n",
        "      PPV = 0\r\n",
        "\r\n",
        "    # Overall accuracy for each class\r\n",
        "    if np.sum(TP+FP+FN+TN) != 0 :\r\n",
        "      ACC = (TP+TN)/(TP+FP+FN+TN)\r\n",
        "      ACC = np.mean(ACC)\r\n",
        "\r\n",
        "    else:\r\n",
        "      ACC = 0\r\n",
        "\r\n",
        "    #UPDATE step\r\n",
        "    if ACC > ACC_round:\r\n",
        "      ACC_round = ACC\r\n",
        "      best_acc_threshold = thr\r\n",
        "\r\n",
        "    if PPV > PPV_round:\r\n",
        "      PPV_round = PPV\r\n",
        "      best_ppv_threshold = thr\r\n",
        "\r\n",
        "    if TPR > TPR_round:\r\n",
        "      TPR_round = TPR\r\n",
        "      best_tpr_threshold = thr\r\n",
        "    \r\n",
        "    if thr > 0.99:\r\n",
        "      done = True\r\n",
        "      print('done')\r\n",
        "      print('ACC score: '+str(ACC_round)+', thr: '+str(best_acc_threshold))\r\n",
        "      print('TPR score: '+str(TPR_round)+', thr: '+str(best_tpr_threshold))\r\n",
        "      print('PPV score: '+str(PPV_round)+', thr: '+str(best_ppv_threshold))\r\n",
        "    \r\n",
        "    thr +=0.001\r\n",
        "  \r\n",
        "  #tpr confusion matrix\r\n",
        "  y_hat_tpr = y_hat > best_tpr_threshold\r\n",
        "\r\n",
        "  tpr_cnf = confusion_matrix(y.argmax(axis=1),y_hat_tpr.argmax(axis=1))\r\n",
        "  plt.figure(figsize = (15,15)) \r\n",
        "  plt.imshow(tpr_cnf, cmap = 'jet')\r\n",
        "  plt.title('TPR confusion matrix')\r\n",
        "  plt.xlabel('predicted')\r\n",
        "  plt.ylabel('true_labels')\r\n",
        "  plt.xticks(range(classes))\r\n",
        "  plt.yticks(range(classes))\r\n",
        "  plt.show() \r\n",
        "  \r\n",
        "  #ppv confusion matrix\r\n",
        "  y_hat_ppv = y_hat > best_ppv_threshold\r\n",
        "\r\n",
        "  ppv_cnf = confusion_matrix(y.argmax(axis=1),y_hat_ppv.argmax(axis=1)) \r\n",
        "  plt.figure(figsize = (15,15)) \r\n",
        "  plt.imshow(ppv_cnf,cmap = 'jet')\r\n",
        "  plt.title('PPV confusion matrix')\r\n",
        "  plt.xlabel('predicted')\r\n",
        "  plt.ylabel('true_labels')\r\n",
        "  plt.xticks(range(classes))\r\n",
        "  plt.yticks(range(classes))\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  #acc confusion matrix\r\n",
        "  y_hat_acc = y_hat > best_acc_threshold\r\n",
        "\r\n",
        "  acc_cnf = confusion_matrix(y.argmax(axis=1),y_hat_acc.argmax(axis=1)) \r\n",
        "  plt.figure(figsize = (15,15)) \r\n",
        "  plt.imshow(acc_cnf,cmap = 'jet')\r\n",
        "  plt.title('ACCURACY confusion matrix')\r\n",
        "  plt.xlabel('predicted')\r\n",
        "  plt.ylabel('true_labels')\r\n",
        "  plt.xticks(range(classes))\r\n",
        "  plt.yticks(range(classes))\r\n",
        "  plt.colorbar()\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBFy5QY64o3m"
      },
      "source": [
        "acc_mat = confusion_matrix(y_test.argmax(axis = 1),y_hat.argmax(axis =1) )\r\n",
        "plt.figure(figsize = (15,15)) \r\n",
        "plt.imshow(acc_mat,cmap = 'jet')\r\n",
        "plt.title('accuracy confusion matrix')\r\n",
        "plt.xlabel('predicted')\r\n",
        "plt.ylabel('true_labels')\r\n",
        "plt.xticks(range(15))\r\n",
        "plt.yticks(range(15))\r\n",
        "plt.colorbar()\r\n",
        "plt.show()\r\n",
        "y_test.argmax(axis=1)\r\n",
        "\r\n",
        "FP = acc_mat.sum(axis=0) - np.diag(acc_mat) \r\n",
        "FN = acc_mat.sum(axis=1) - np.diag(acc_mat)\r\n",
        "TP = np.diag(acc_mat)\r\n",
        "TN = acc_mat.sum() - (FP + FN + TP)\r\n",
        "\r\n",
        "FP = FP.astype(float)\r\n",
        "FN = FN.astype(float)\r\n",
        "TP = TP.astype(float)\r\n",
        "TN = TN.astype(float)\r\n",
        "# Sensitivity, hit rate, recall, or true positive rate\r\n",
        "TPR = TP/(TP+FN)\r\n",
        "print(np.sum(TPR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojAafKHI4wqG"
      },
      "source": [
        "fpr, tpr, roc_thresholds, classes = ROC_curve(y_test,y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFjlQgQb4y24"
      },
      "source": [
        "precision, recall, prc_thresholds = PRC_curve(y_test,y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA4xdWk4BBmd"
      },
      "source": [
        "recall.values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDemdUaI40j7"
      },
      "source": [
        "operating_points(y_test,y_hat,classes)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}