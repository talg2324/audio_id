{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tals_feat_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfv7Qr_gskpu"
      },
      "source": [
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from scipy import stats, signal\r\n",
        "from keras.models import Model, Sequential\r\n",
        "from keras.layers import Conv2D,Conv1D, Dropout, MaxPooling2D, Flatten, Dense, Input , concatenate, MaxPooling1D, BatchNormalization\r\n",
        "from keras.losses import categorical_crossentropy\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras import metrics\r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO3J-BRZua7u",
        "outputId": "89d6c21c-525a-4c36-9c5d-22dd52979708"
      },
      "source": [
        "drive.mount('/content/gdrive')\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRSdgX8duqOU"
      },
      "source": [
        "# # Yariv\r\n",
        "# feat_space = './drive/MyDrive/audio_colab/Features/'\r\n",
        "\r\n",
        "# Tal\r\n",
        "feat_space = './drive/MyDrive/Voice Recording Database/Features/'\r\n",
        "\r\n",
        "X = {}\r\n",
        "Y = {}\r\n",
        "\r\n",
        "class_no = 0\r\n",
        "stat_names =[\r\n",
        "        'spectral_centroid',\r\n",
        "        'spectral_bandwidth',\r\n",
        "        'rms',\r\n",
        "        'zero_crossing_rate']\r\n",
        "\r\n",
        "mel_orders = ['mfcc', 'del-mfcc', 'del-del-mfcc']\r\n",
        "\r\n",
        "for spect_path in os.listdir(feat_space):\r\n",
        "    data = {}\r\n",
        "    if '.npy' in spect_path and 'Copy' not in spect_path:\r\n",
        "      label, ind = spect_path.split('_')\r\n",
        "\r\n",
        "      obj = np.load(feat_space+spect_path, allow_pickle=True)\r\n",
        "      stats = obj[0,0]\r\n",
        "      data['STFT'] = obj[0,1]\r\n",
        "      mel = obj[0,2]\r\n",
        "      data['Spect'] = obj[0,3]\r\n",
        "      data['dSdT'] = obj[0,4]\r\n",
        "      data['dS2dT2'] = obj[0,5]\r\n",
        "\r\n",
        "      for i in range(len(stat_names)):\r\n",
        "          data[stat_names[i]] = stats[i,:]\r\n",
        "\r\n",
        "      for i in range(len(mel_orders)):\r\n",
        "          data[mel_orders[i]] = mel[i, :, :]\r\n",
        "\r\n",
        "      if label not in Y.keys():\r\n",
        "          Y[label] = class_no\r\n",
        "          X[class_no] = []\r\n",
        "          class_no += 1\r\n",
        "\r\n",
        "      this_class = Y[label]\r\n",
        "      X[this_class].append(data)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqq8bxblwSfa"
      },
      "source": [
        "X_train = []\r\n",
        "Y_train = []\r\n",
        "for i in range(class_no):\r\n",
        "    X_train.extend(X[i])\r\n",
        "    Y_train.extend([l for l in range(len(X[i]))])\r\n",
        "\r\n",
        "X_train = np.array(X_train)\r\n",
        "Y_train = np.array(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRdSlJKgx0MB"
      },
      "source": [
        "def get_model_block(inp_shape, dims, p=0.05):\r\n",
        "\r\n",
        "    if dims=='image':\r\n",
        "\r\n",
        "      inp = Input(shape= (inp_shape[0], inp_shape[1], 1))\r\n",
        "      x = Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=inp_shape)(inp)\r\n",
        "      x = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\r\n",
        "      x = MaxPooling2D(pool_size=(2,2))(x)\r\n",
        "      x = Dropout(p)(x)\r\n",
        "      connection_layer = Flatten()(x)\r\n",
        "\r\n",
        "    if dims=='coeffs':\r\n",
        "\r\n",
        "      inp = Input(shape= (inp_shape[0], inp_shape[1], 1))\r\n",
        "      x = Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=inp_shape)(inp)\r\n",
        "      x = MaxPooling2D(pool_size=(2,2))(x)\r\n",
        "      x = BatchNormalization()(x)\r\n",
        "      x = Dropout(p)(x)\r\n",
        "      connection_layer = Flatten()(x)\r\n",
        "\r\n",
        "    if dims=='stats':\r\n",
        "      inp = Input(shape = (inp_shape[0],1) )\r\n",
        "      x = Conv1D(32, kernel_size=3, activation='relu')(inp)\r\n",
        "      x = Conv1D(32, kernel_size=3, activation='relu')(x)\r\n",
        "      x =  MaxPooling1D(2)(x)\r\n",
        "      x = BatchNormalization()(x)\r\n",
        "      x = Dropout(p)(x)\r\n",
        "      connection_layer = Flatten()(x)\r\n",
        "\r\n",
        "    m = Model(inputs = inp,outputs = connection_layer)\r\n",
        "\r\n",
        "    return m\r\n",
        "\r\n",
        "def model_output(models,num_class,lr=1e-3):\r\n",
        "\r\n",
        "    if len(models) > 1 :\r\n",
        "      outputs = concatenate([ m.output for m in models ])\r\n",
        "      inputs = [ m.input for m in models ] \r\n",
        "\r\n",
        "    else:\r\n",
        "      outputs = concatenate([models[0].output,models[0].output])\r\n",
        "      inputs = [models[0].input]\r\n",
        "\r\n",
        "    x = Dense(256,activation='relu')(outputs)\r\n",
        "    x = Dense(128, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Dropout(0.3)(x)\r\n",
        "    x = Dense(32, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Dropout(0.3)(x)\r\n",
        "    output_layer = Dense(num_class, activation='softmax')(x)\r\n",
        "\r\n",
        "    opt = Adam(lr)\r\n",
        "    m = Model(inputs = inputs ,outputs = output_layer)\r\n",
        "    m.compile(loss=categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\r\n",
        "    return m "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je6Nk5wAyub1"
      },
      "source": [
        "feats = ['rms', 'mfcc','']\r\n",
        "dims = {'rms':'stats','STFT':'image','Spect':'image','mfcc':'coeffs','del-mfcc':'coeffs','del-del-mfcc':'coeffs'}\r\n",
        "classes = Y_train.max()+1\r\n",
        "class_labels = np.zeros((classes))\r\n",
        "Y_train2 = []\r\n",
        "\r\n",
        "for y in Y_train:\r\n",
        "    t = np.copy(class_labels)\r\n",
        "    t[y] = 1\r\n",
        "    Y_train2.append(t)\r\n",
        "\r\n",
        "Y_train2 = np.array(Y_train2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqhd4JDGOS8x"
      },
      "source": [
        "def reshape_data(feat, X):\r\n",
        "  try:\r\n",
        "    h,w = X[0][feat].shape\r\n",
        "    X_i = np.array([x[feat].reshape(h,w,1) for x in X])\r\n",
        "  except:\r\n",
        "    X_i = np.array([x[feat].reshape(-1,1) for x in X])\r\n",
        "\r\n",
        "  return [X_i]\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsRK2a8q4-ao",
        "outputId": "0eda0787-a853-4d82-dc58-9db5a43ec6fe"
      },
      "source": [
        "done=False\r\n",
        "best_loss = 100\r\n",
        "best_feats = []\r\n",
        "\r\n",
        "while not done:\r\n",
        "  losses = []\r\n",
        "  x_test_round, x_train_round, y_test_round, y_train_round = train_test_split(X_train, Y_train2, test_size=0.75, random_state=7)\r\n",
        "  m_list = []\r\n",
        "  x_train = []\r\n",
        "  x_test = []\r\n",
        "\r\n",
        "  if len(best_feats):\r\n",
        "    for f in best_feats :\r\n",
        "      x_train.append(reshape_data(f, x_train_round))\r\n",
        "      x_test.append(reshape_data(f, x_test_round))\r\n",
        "      m_list.append(get_model_block(x_train_round[0][f].shape, dims[f]))\r\n",
        "\r\n",
        "  for f in feats:\r\n",
        "    if f not in best_feats:\r\n",
        "      print(f)\r\n",
        "      print(len(m_list))\r\n",
        "      x_train_i = []\r\n",
        "      x_test_i = []\r\n",
        "\r\n",
        "      x_train_i.extend([block for block in x_train])\r\n",
        "      x_test_i.extend([block for block in x_test])\r\n",
        "\r\n",
        "      x_train_i.append(reshape_data(f, x_train_round))\r\n",
        "      x_test_i.append(reshape_data(f, x_test_round))\r\n",
        "\r\n",
        "      m_list.append(get_model_block(x_train_round[0][f].shape,dims[f]))\r\n",
        "\r\n",
        "      m = model_output(m_list, num_class=Y_train.max()+1,lr=1e-4)\r\n",
        "\r\n",
        "      if len(m_list) > 1:\r\n",
        "        m.fit(x_train_i, y_train_round, epochs=20, batch_size=16, verbose=0)\r\n",
        "        loss, acc = m.evaluate(x_test_i, y_test_round, batch_size=16)\r\n",
        "      else:\r\n",
        "        m.fit(x_train_i[0], y_train_round, epochs=20, batch_size=16, verbose=0)\r\n",
        "        loss, acc = m.evaluate(x_test_i[0][0], y_test_round, batch_size=16)\r\n",
        "\r\n",
        "      losses.append(loss)\r\n",
        "      m_list.pop()\r\n",
        "\r\n",
        "  best_round = min(losses)\r\n",
        "  best_feat_round = losses.index(best_round)\r\n",
        "  if best_round < best_loss*0.9:\r\n",
        "    best_loss = best_round\r\n",
        "    best_feats.append(feats[best_feat_round])\r\n",
        "  else:\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rms\n",
            "0\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efda345ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.4891 - accuracy: 0.1250\n",
            "mfcc\n",
            "0\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efda85e08c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.9546 - accuracy: 0.0417\n",
            "mfcc\n",
            "1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efda538b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.7986 - accuracy: 0.1250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5qqXp_P5H-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b9871c-07a7-465a-94b2-a41fdcae8f4a"
      },
      "source": [
        "print(best_feats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rms']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCbjGDP2tq9K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}